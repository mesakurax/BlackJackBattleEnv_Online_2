重要提醒：
1.请注意各文件夹、文件名和类名要遵照格式来，模型导入路径使用相对路径，不然会扣分！！！
2.为了方便助教工作，辛苦大家统一版本：python=3.9；tensorflow=2.12.0；pytorch=1.13.1~

*********************************************************************************************************

比赛规则：
1.两两对打，所有小组都会互相成为对手；按得分，选择一半的队伍进入下一阶段；
2.比赛分阶段进行，每一阶段会淘汰掉一半的小组，并且随着阶段推进，对打轮次会增加；
（具体来说，第一阶段，小组A会和班上其他全部小组都比赛，每场比赛2000次并且每个组会获得该轮比赛得分，如果小组A的所有得分和大于0将进入下一阶段比赛，
下一阶段比赛每一对比赛5000次，以后每轮增加5000次。）

*********************************************************************************************************

测试方法：
这个项目是基于最终测试的框架改的，主要测试接口是否正确，另外也可以测试自己目前策略和一些基础策略对抗时的胜率。
想要测试自己的策略的话：
1.将自己的项目文件夹重命名为Group_X（X是你的组号）放入StudentCode
2.打开StudentCode/__init__.py，把第4行“from StudentCode.Group_X.实现策略类的那个py文件"改成自己实现策略类的那个py文件，后面"Policy_X"对应自己实现策略的那个类。如果你们的代码涉及读取模型或者策略的话，可以后面加上用于加载的代码，第6行是一个范例。
3.运行test_agent.py文件，如果每组实验重复100000次对你们的电脑负担太大的话，可以在第135行"num_round = 100000"那里修改重复次数，由于这个次数中双方各担任一半次数的庄家/闲家，建议修改结果保持为偶数。
运行成功的话：
可以在得分表中查看最终分数和平均得分（计算平均得分的代码不太聪明会把自己也算进去）
可以在score.log中查看每两队间对局具体的胜场/平场/负场
可以在test.log中查看详细的对局记录（当重复次数大的时候这个文件一般会非常非常大，建议把num_round调为10-1000再来看）

*********************************************************************************************************

更新以后策略类需要有两个策略函数act_player和act_dealer，分别对应闲家策略和庄家策略。不过这两个策略的参数和输出格式是完全一致的，理论上直接将闲家策略用于庄家策略、或者庄家策略直接保持17点策略都是不错的选择，具体什么策略最好还需要你们亲自实验一下。

tips:如果你安装库的时候遇到了困难，一些不保证是最优解但是亲测有效的方法：
1.conda更换镜像源：https://www.cnblogs.com/yang-xin/p/9007723.html
2.如果conda install tensorflow遇到了奇奇怪怪的问题，可以尝试pip install tensorflow

*********************************************************************************************************

以下内容写给助教：
测试方法
1.把每一组提交的Group放进StudentCode文件夹（然后Debug）
2.在StudentCode/__init__.py里制作每一组（包括默认庄家策略，即Agent17）的对象，放进一个列表
3.制作对应的名单表，用于结果展示
4.运行test_agent.py（可以在第135行改变对战次数）
5.等待结果（包括得分记录score.log、过程详细记录test.log以及表格“得分表.xlsx”）
如果要打多轮淘汰赛的话，修改23步中的列表并重新执行步骤45（可随队伍数量减少而提高对战次数），直到最后抉择出总冠军。

